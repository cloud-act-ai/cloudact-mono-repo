# GCP Cost Billing Pipeline
# Extracts billing data from GCP billing export and loads into organization cost dataset
# Usage: POST /api/v1/pipelines/run/{org_slug}/gcp/cost/cost_billing
#
# PREREQUISITES:
# 1. Organization must have a valid GCP_SA integration configured
# 2. The GCP Service Account must have BigQuery read access to the billing export table
#
# The pipeline will:
# 1. Decrypt the organization's GCP Service Account credentials
# 2. Use those credentials to query the billing export table
# 3. Load the data into the organization's cost dataset

pipeline_id: "{org_slug}-gcp-cost-billing"
description: "Extract GCP billing costs for organization {org_slug} - date {date}"

# Pipeline-level variables
# These can be overridden via API request body
variables:
  source_billing_table: "gac-prod-471220.cloudact_cost_usage.gcp_billing_export_resource_v1_01ECB7_6EE0BA_7357F1"
  destination_dataset_type: "gcp_silver_cost"
  destination_table: "billing_cost_daily"
  admin_email: "admin@example.com"  # Override via API request body
  use_org_credentials: "false"  # Set to "true" to use org's GCP credentials

steps:
  # Step 0 (Optional): Decrypt GCP credentials for customer's billing data
  # Skip this step if use_org_credentials is false
  - step_id: "decrypt_gcp_credentials"
    name: "Load Organization GCP Credentials"
    ps_type: "integrations.kms_decrypt"
    enabled: "{use_org_credentials}"
    config:
      provider: "GCP_SA"
      require_valid: true
      context_key: "gcp_sa_json"
    on_failure: "continue"  # Pipeline can continue with default credentials

  # Step 1: Extract billing data from GCP billing export
  - step_id: "extract_billing_costs"
    name: "Extract GCP Billing Costs"
    ps_type: "gcp.bq_etl"
    timeout_minutes: 20

    # Source configuration (at step level, not in config!)
    source:
      bq_project_id: "gac-prod-471220"
      query: |
        SELECT
          billing_account_id,
          service.id AS service_id,
          service.description AS service_description,
          sku.id AS sku_id,
          sku.description AS sku_description,
          usage_start_time,
          usage_end_time,
          project.id AS project_id,
          project.name AS project_name,
          project.number AS project_number,
          location.location AS location_location,
          location.region AS location_region,
          location.zone AS location_zone,
          resource.name AS resource_name,
          resource.global_name AS resource_global_name,
          cost,
          currency,
          currency_conversion_rate,
          usage.amount AS usage_amount,
          usage.unit AS usage_unit,
          usage.amount_in_pricing_units AS usage_amount_in_pricing_units,
          usage.pricing_unit AS usage_pricing_unit,
          cost_type,
          (SELECT IFNULL(SUM(amount), 0.0) FROM UNNEST(credits)) AS credits_total,
          cost_at_list,
          invoice.month AS invoice_month,
          CURRENT_DATE() AS ingestion_date,
          TO_JSON_STRING(ARRAY(SELECT AS STRUCT key, value FROM UNNEST(labels))) AS labels_json,
          TO_JSON_STRING(ARRAY(SELECT AS STRUCT key, value FROM UNNEST(system_labels))) AS system_labels_json
        FROM `{source_billing_table}`
        WHERE DATE(usage_start_time) = '{date}'
        LIMIT 1000

    # Destination configuration (at step level, not in config!)
    destination:
      bq_project_id: "gac-prod-471220"
      dataset_type: "{destination_dataset_type}"
      table: "{destination_table}"
      write_mode: "append"
      schema_template: "billing_cost"
      table_config:
        time_partitioning:
          field: "ingestion_date"
          type: "DAY"
          expiration_days: 730
        clustering_fields:
          - "billing_account_id"
          - "service_id"
          - "project_id"
          - "location_region"

  # Step 2: Notification on failure
  - step_id: "notify_on_failure"
    name: "Send Failure Notification"
    ps_type: "notify_systems.email_notification"
    trigger: "on_failure"
    to_emails:
      - "{admin_email}"
      - "data-ops@example.com"  # System admin email
    subject: "[ALERT] Cost Billing Pipeline Failed - {org_slug}"
    message: |
      ALERT: The GCP cost billing pipeline has failed!

      Organization: {org_slug}
      Pipeline: {pipeline_id}
      Run Date: {date}
      Trigger By: {trigger_by}

      Destination: {destination_dataset_type}.{destination_table}

      Please investigate the logs in:
      organizations.org_meta_step_logs (filter by org_slug={org_slug})
      organizations.org_meta_pipeline_runs (filter by org_slug={org_slug})
