# Organization Onboarding Pipeline Template
# Creates organization infrastructure (dataset + metadata tables)
# Called automatically during: POST /api/v1/organizations/onboard

pipeline_id: "{org_slug}-organization-onboarding"
description: "Onboard new organization {org_slug} - create dataset and metadata infrastructure"

# Pipeline-level variables
# These can be overridden via API request body
variables:
  gcp_project_id: "gac-prod-471220"
  location: "US"
  dataset_id: "{org_slug}"  # Organization-specific dataset
  admin_email: "admin@example.com"  # Override via API request body

steps:
  # Step 1: Create organization metadata infrastructure
  - step_id: "create_infrastructure"
    name: "Create Organization Dataset and Metadata Tables"
    ps_type: "setup.organizations.onboarding"
    timeout_minutes: 10

    config:
      gcp_project_id: "{gcp_project_id}"
      dataset_id: "{dataset_id}"
      location: "{location}"

      # Default quota limits for new organizations
      default_daily_limit: 50      # Daily pipeline runs allowed
      default_monthly_limit: 1000  # Monthly pipeline runs allowed
      default_concurrent_limit: 5  # Concurrent pipelines allowed

      # Metadata tables are NOW in central 'organizations' dataset:
      # - org_meta_pipeline_runs (pipeline execution logs)
      # - org_meta_step_logs (step-by-step execution logs)
      # - org_meta_dq_results (data quality validation results)
      #
      # Per-organization dataset contains ONLY:
      # - Data tables (gcp_cost_billing, etc.)
      # - Optional validation/test tables
      metadata_tables: []

      # Validation test
      create_validation_table: true
      validation_table_name: "onboarding_validation_test"

  # Step 2: Send welcome email notification
  - step_id: "send_welcome_email"
    name: "Send Welcome Email to Admin"
    ps_type: "notify_systems.email_notification"
    trigger: "on_success"  # Only send on successful onboarding

    to_emails:
      - "{admin_email}"

    subject: "Welcome to Convergence Data Pipeline - Organization {org_slug} Onboarded"

    message: |
      Welcome to Convergence Data Pipeline!

      Your organization has been successfully onboarded:

      Organization: {org_slug}
      Dataset: {gcp_project_id}.{dataset_id}
      Location: {location}
      Onboarding Date: {run_date}

      Infrastructure Created:
      - BigQuery Dataset: {dataset_id}
      - Metadata Tables: Centralized in 'organizations' dataset (org_*, org_meta_*)
      - API Key: Generated (stored in central organizations dataset)

      Next Steps:
      1. Save your API key securely (shown once during onboarding)
      2. Configure your pipelines in configs/{provider}/{domain}/
      3. Run your first pipeline:
         POST /api/v1/pipelines/run/{org_slug}/gcp/cost/cost_billing

      Documentation: https://github.com/your-org/convergence-data-pipeline

      Questions? Contact: {admin_email}

  # Step 3: Notification on failure
  - step_id: "notify_on_failure"
    name: "Send Failure Notification"
    ps_type: "notify_systems.email_notification"
    trigger: "on_failure"

    to_emails:
      - "{admin_email}"
      - "data-ops@example.com"  # System admin email

    subject: "[ALERT] Organization Onboarding Failed - {org_slug}"

    message: |
      ALERT: Organization onboarding has failed!

      Organization: {org_slug}
      Pipeline: {pipeline_id}
      Run Date: {run_date}
      Trigger By: {trigger_by}

      Please investigate the logs in:
      {gcp_project_id}.organizations.org_meta_step_logs (filter by org_slug={org_slug})

      Or check the onboarding endpoint logs.
