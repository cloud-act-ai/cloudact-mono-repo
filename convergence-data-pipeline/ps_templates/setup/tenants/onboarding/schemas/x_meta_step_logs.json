[
  {
    "name": "step_logging_id",
    "type": "STRING",
    "mode": "REQUIRED",
    "description": "Unique identifier (UUID) for this specific step execution within a pipeline run. Used to track individual step performance and correlate with external monitoring systems. Each step execution gets a unique ID even across retries."
  },
  {
    "name": "pipeline_logging_id",
    "type": "STRING",
    "mode": "REQUIRED",
    "description": "Foreign key linking to pipeline_runs.pipeline_logging_id. Associates this step execution with its parent pipeline run. Used for aggregating all steps that belong to a single pipeline execution and calculating total pipeline duration."
  },
  {
    "name": "step_name",
    "type": "STRING",
    "mode": "REQUIRED",
    "description": "Human-readable name/identifier of the step from pipeline YAML configuration. Examples: 'extract_customer_data', 'transform_pricing', 'load_to_warehouse', 'data_quality_check'. Corresponds to the 'step_id' field in pipeline YAML. Used for filtering, aggregation, and identifying which step failed."
  },
  {
    "name": "step_type",
    "type": "STRING",
    "mode": "REQUIRED",
    "description": "Type of operation this step performs. Valid values: 'gcp.bq_etl' (BQ data transfer/transformation), 'setup.tenants.onboarding' (tenant infrastructure setup), 'notify_systems.email_notification' (email notifications), 'notify_systems.slack_notification' (Slack notifications), 'aws.s3_data_loader' (S3 data operations), 'custom' (user-defined processor). Used for step-type-specific analytics and identifying common failure patterns by type."
  },
  {
    "name": "step_index",
    "type": "INTEGER",
    "mode": "REQUIRED",
    "description": "Zero-based sequential position of this step in the pipeline definition (order in YAML file). Step 0 is first, step 1 is second, etc. Does NOT reflect execution order in parallel pipelines (steps may execute out of order due to DAG dependencies). Used for understanding pipeline structure and visualizing execution flow."
  },
  {
    "name": "status",
    "type": "STRING",
    "mode": "REQUIRED",
    "description": "Execution status of this step. Valid values: 'PENDING' (not started), 'RUNNING' (currently executing), 'COMPLETED' (successfully finished), 'FAILED' (encountered error), 'SKIPPED' (skipped due to conditional logic). Used for step-level monitoring, retry logic, and identifying partial pipeline failures."
  },
  {
    "name": "start_time",
    "type": "TIMESTAMP",
    "mode": "REQUIRED",
    "description": "UTC timestamp when this step started execution. Used for partitioning (daily partitions by step start time), calculating step duration, identifying slow steps, and analyzing parallel execution patterns. Partition key for this table."
  },
  {
    "name": "end_time",
    "type": "TIMESTAMP",
    "mode": "NULLABLE",
    "description": "UTC timestamp when step execution completed (success or failure). NULL while step is still running. Used to calculate step execution duration (end_time - start_time) and identify stuck steps that never completed."
  },
  {
    "name": "duration_ms",
    "type": "INTEGER",
    "mode": "NULLABLE",
    "description": "Total step execution time in milliseconds from start to completion. Pre-calculated as (end_time - start_time) for query performance. NULL while step is running. Used for step performance analytics, identifying bottlenecks, optimizing parallel execution, and SLA monitoring at step granularity."
  },
  {
    "name": "rows_processed",
    "type": "INTEGER",
    "mode": "NULLABLE",
    "description": "Number of data rows processed/written by this step. For gcp.bq_etl steps: rows inserted/updated. For data quality steps: rows validated. NULL for steps that don't process rows (notifications, setup operations). Used for data volume tracking, cost attribution, and identifying large data movement operations."
  },
  {
    "name": "error_message",
    "type": "STRING",
    "mode": "NULLABLE",
    "description": "Detailed error message if step failed. Contains exception class, error description, relevant context (table names, query snippets, validation failures). NULL for successful steps. Used for debugging step failures, creating alerts, and error categorization. Max recommended length: 10KB."
  },
  {
    "name": "user_id",
    "type": "STRING",
    "mode": "NULLABLE",
    "description": "User UUID from frontend (X-User-ID header). Tracks which specific user triggered the parent pipeline execution. NULL for scheduler-triggered or system-triggered pipelines. Inherited from parent pipeline run. Used for user-level analytics and audit trails. Example: 'f47ac10b-58cc-4372-a567-0e02b2c3d479'."
  },
  {
    "name": "metadata",
    "type": "JSON",
    "mode": "NULLABLE",
    "description": "Step-specific execution metadata as flexible JSON object. Schema varies by step_type. Examples: For gcp.bq_etl: {'destination_table': 'dataset.table', 'bytes_processed': 12345678, 'query_cost_usd': 0.05}. For data_quality: {'total_checks': 15, 'passed_count': 14, 'failed_count': 1, 'failed_expectations': [...]}. For notifications: {'recipients': ['email@example.com'], 'status': 'sent'}. JSON type provides schema flexibility for different step types without table alterations. Used for detailed step analytics, cost tracking, and audit trails."
  }
]
