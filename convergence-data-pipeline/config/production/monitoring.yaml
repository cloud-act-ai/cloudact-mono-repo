# ============================================
# Convergence Data Pipeline - Monitoring Configuration
# ============================================
# Metrics, alerts, and dashboards

# ============================================
# Prometheus Metrics Configuration
# ============================================
prometheus:
  enabled: true
  port: 9090
  path: /metrics
  export_interval_seconds: 60

  # Metric labels (added to all metrics)
  global_labels:
    service: convergence-data-pipeline
    environment: ${ENVIRONMENT}
    version: ${APP_VERSION}

  # Custom metrics
  metrics:
    # Request metrics
    - name: http_requests_total
      type: counter
      description: "Total HTTP requests"
      labels:
        - method
        - path
        - status_code
        - tenant_id

    - name: http_request_duration_seconds
      type: histogram
      description: "HTTP request duration in seconds"
      buckets: [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
      labels:
        - method
        - path
        - tenant_id

    - name: http_request_size_bytes
      type: histogram
      description: "HTTP request size in bytes"
      buckets: [100, 1000, 10000, 100000, 1000000, 10000000]
      labels:
        - method
        - path

    - name: http_response_size_bytes
      type: histogram
      description: "HTTP response size in bytes"
      buckets: [100, 1000, 10000, 100000, 1000000, 10000000]
      labels:
        - method
        - path

    # Pipeline metrics
    - name: pipeline_executions_total
      type: counter
      description: "Total pipeline executions"
      labels:
        - tenant_id
        - pipeline_id
        - status

    - name: pipeline_execution_duration_seconds
      type: histogram
      description: "Pipeline execution duration in seconds"
      buckets: [1, 5, 10, 30, 60, 120, 300, 600, 1800, 3600]
      labels:
        - tenant_id
        - pipeline_id

    - name: pipeline_rows_processed_total
      type: counter
      description: "Total rows processed by pipelines"
      labels:
        - tenant_id
        - pipeline_id

    - name: pipeline_errors_total
      type: counter
      description: "Total pipeline errors"
      labels:
        - tenant_id
        - pipeline_id
        - error_type

    - name: pipeline_retries_total
      type: counter
      description: "Total pipeline retries"
      labels:
        - tenant_id
        - pipeline_id

    # Rate limiting metrics
    - name: rate_limit_hits_total
      type: counter
      description: "Total rate limit hits"
      labels:
        - tenant_id
        - limit_type

    - name: rate_limit_remaining
      type: gauge
      description: "Remaining rate limit quota"
      labels:
        - tenant_id
        - limit_type

    # Authentication metrics
    - name: auth_requests_total
      type: counter
      description: "Total authentication requests"
      labels:
        - tenant_id
        - status

    - name: auth_failures_total
      type: counter
      description: "Total authentication failures"
      labels:
        - tenant_id
        - reason

    # BigQuery metrics
    - name: bigquery_queries_total
      type: counter
      description: "Total BigQuery queries"
      labels:
        - tenant_id
        - dataset
        - status

    - name: bigquery_query_duration_seconds
      type: histogram
      description: "BigQuery query duration in seconds"
      buckets: [0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0]
      labels:
        - tenant_id
        - dataset

    - name: bigquery_bytes_processed_total
      type: counter
      description: "Total bytes processed by BigQuery"
      labels:
        - tenant_id
        - dataset

    - name: bigquery_errors_total
      type: counter
      description: "Total BigQuery errors"
      labels:
        - tenant_id
        - error_type

    # Metadata logging metrics
    - name: metadata_logs_total
      type: counter
      description: "Total metadata logs written"
      labels:
        - tenant_id
        - log_type

    - name: metadata_log_batch_size
      type: histogram
      description: "Metadata log batch size"
      buckets: [1, 10, 25, 50, 100, 250, 500, 1000]

    - name: metadata_log_queue_size
      type: gauge
      description: "Current metadata log queue size"

    # System metrics
    - name: system_cpu_usage_percent
      type: gauge
      description: "System CPU usage percentage"

    - name: system_memory_usage_bytes
      type: gauge
      description: "System memory usage in bytes"

    - name: system_disk_usage_bytes
      type: gauge
      description: "System disk usage in bytes"

    - name: active_connections
      type: gauge
      description: "Number of active connections"

    - name: goroutines_total
      type: gauge
      description: "Number of goroutines"

# ============================================
# Health Check Configuration
# ============================================
health_checks:
  # Liveness probe
  liveness:
    enabled: true
    path: /health/live
    interval_seconds: 10
    timeout_seconds: 5
    failure_threshold: 3

  # Readiness probe
  readiness:
    enabled: true
    path: /health/ready
    interval_seconds: 30
    timeout_seconds: 10
    failure_threshold: 3

    # Dependencies to check
    dependencies:
      - name: bigquery
        type: gcp_service
        critical: true
        timeout_seconds: 5

      - name: firestore
        type: gcp_service
        critical: true
        timeout_seconds: 5

      - name: secret_manager
        type: gcp_service
        critical: false
        timeout_seconds: 5

# ============================================
# SLI/SLO Configuration
# ============================================
sli_slo:
  # Availability SLO
  availability:
    target: 99.9  # 99.9% uptime
    window: 30d
    measurement: uptime_ratio

  # Latency SLO
  latency:
    p50:
      target: 100  # 100ms
      window: 30d
    p95:
      target: 500  # 500ms
      window: 30d
    p99:
      target: 1000  # 1s
      window: 30d

  # Error rate SLO
  error_rate:
    target: 0.1  # 0.1% error rate
    window: 30d
    measurement: error_ratio

  # Success rate SLO
  success_rate:
    target: 99.9  # 99.9% success rate
    window: 30d
    measurement: success_ratio

# ============================================
# Alert Configuration
# ============================================
alerts:
  # High error rate
  - name: HighErrorRate
    severity: critical
    condition: rate(http_requests_total{status_code=~"5.."}[5m]) > 0.05
    duration: 5m
    description: "Error rate is above 5% for 5 minutes"
    runbook: docs/operations/RUNBOOK.md#high-error-rate

  # High latency
  - name: HighLatency
    severity: warning
    condition: histogram_quantile(0.95, http_request_duration_seconds) > 1.0
    duration: 10m
    description: "95th percentile latency is above 1 second for 10 minutes"
    runbook: docs/operations/RUNBOOK.md#high-latency

  # Pipeline failures
  - name: PipelineFailures
    severity: high
    condition: rate(pipeline_executions_total{status="failed"}[15m]) > 0.1
    duration: 5m
    description: "Pipeline failure rate is above 10% for 5 minutes"
    runbook: docs/operations/RUNBOOK.md#pipeline-failures

  # Rate limit exceeded
  - name: RateLimitExceeded
    severity: medium
    condition: rate(rate_limit_hits_total[5m]) > 10
    duration: 5m
    description: "Rate limit hits are high (>10/min) for 5 minutes"
    runbook: docs/operations/RUNBOOK.md#rate-limit-exceeded

  # Authentication failures
  - name: AuthenticationFailures
    severity: high
    condition: rate(auth_failures_total[5m]) > 5
    duration: 2m
    description: "Authentication failures are high (>5/min) for 2 minutes"
    runbook: docs/operations/RUNBOOK.md#auth-failures

  # BigQuery errors
  - name: BigQueryErrors
    severity: high
    condition: rate(bigquery_errors_total[10m]) > 0.05
    duration: 5m
    description: "BigQuery error rate is above 5% for 5 minutes"
    runbook: docs/operations/RUNBOOK.md#bigquery-errors

  # High CPU usage
  - name: HighCPUUsage
    severity: warning
    condition: system_cpu_usage_percent > 80
    duration: 10m
    description: "CPU usage is above 80% for 10 minutes"
    runbook: docs/operations/RUNBOOK.md#high-cpu-usage

  # High memory usage
  - name: HighMemoryUsage
    severity: warning
    condition: system_memory_usage_bytes / system_memory_total_bytes > 0.9
    duration: 10m
    description: "Memory usage is above 90% for 10 minutes"
    runbook: docs/operations/RUNBOOK.md#high-memory-usage

  # Service down
  - name: ServiceDown
    severity: critical
    condition: up == 0
    duration: 1m
    description: "Service is down for 1 minute"
    runbook: docs/operations/RUNBOOK.md#service-down

  # Metadata log queue full
  - name: MetadataLogQueueFull
    severity: high
    condition: metadata_log_queue_size > 900
    duration: 5m
    description: "Metadata log queue is near capacity (>90%) for 5 minutes"
    runbook: docs/operations/RUNBOOK.md#metadata-queue-full

# ============================================
# Notification Channels
# ============================================
notification_channels:
  # PagerDuty
  pagerduty:
    enabled: true
    integration_key: ${PAGERDUTY_INTEGRATION_KEY}
    severity_mapping:
      critical: high
      high: high
      medium: low
      warning: low

  # Slack
  slack:
    enabled: true
    webhook_url: ${SLACK_WEBHOOK_URL}
    channel: "#alerts-convergence"
    severity_mapping:
      critical: "@channel"
      high: "@here"
      medium: ""
      warning: ""

  # Email
  email:
    enabled: true
    smtp_host: ${EMAIL_SMTP_HOST}
    smtp_port: ${EMAIL_SMTP_PORT}
    from: alerts@cloudact.io
    to:
      - oncall@cloudact.io
      - ops-team@cloudact.io

# ============================================
# Dashboard Configuration
# ============================================
dashboards:
  # System overview
  - name: system_overview
    refresh: 30s
    panels:
      - title: Request Rate
        metric: rate(http_requests_total[5m])
        visualization: graph

      - title: Error Rate
        metric: rate(http_requests_total{status_code=~"5.."}[5m])
        visualization: graph

      - title: Latency (p50, p95, p99)
        metrics:
          - histogram_quantile(0.50, http_request_duration_seconds)
          - histogram_quantile(0.95, http_request_duration_seconds)
          - histogram_quantile(0.99, http_request_duration_seconds)
        visualization: graph

      - title: Active Connections
        metric: active_connections
        visualization: gauge

  # Pipeline metrics
  - name: pipeline_metrics
    refresh: 1m
    panels:
      - title: Pipeline Executions
        metric: rate(pipeline_executions_total[5m])
        visualization: graph

      - title: Pipeline Success Rate
        metric: rate(pipeline_executions_total{status="success"}[5m]) / rate(pipeline_executions_total[5m])
        visualization: gauge

      - title: Pipeline Duration
        metric: histogram_quantile(0.95, pipeline_execution_duration_seconds)
        visualization: graph

      - title: Rows Processed
        metric: rate(pipeline_rows_processed_total[5m])
        visualization: graph

  # BigQuery metrics
  - name: bigquery_metrics
    refresh: 1m
    panels:
      - title: Query Rate
        metric: rate(bigquery_queries_total[5m])
        visualization: graph

      - title: Query Duration
        metric: histogram_quantile(0.95, bigquery_query_duration_seconds)
        visualization: graph

      - title: Bytes Processed
        metric: rate(bigquery_bytes_processed_total[5m])
        visualization: graph

      - title: Error Rate
        metric: rate(bigquery_errors_total[5m])
        visualization: graph

# ============================================
# Trace Configuration
# ============================================
tracing:
  enabled: true
  sample_rate: 0.1  # 10% sampling

  # OpenTelemetry configuration
  otlp:
    endpoint: ${OTEL_EXPORTER_OTLP_ENDPOINT}
    protocol: grpc
    timeout_seconds: 10

  # Trace attributes
  attributes:
    - service.name
    - service.version
    - deployment.environment
    - tenant.id
    - pipeline.id
    - request.id

  # Instrumentation
  instrumentation:
    - fastapi
    - httpx
    - requests
    - google.cloud.bigquery
    - sqlalchemy

# ============================================
# Log-based Metrics
# ============================================
log_metrics:
  # Create metrics from log patterns
  - name: pipeline_step_duration
    pattern: "Pipeline step .* completed in (\\d+)ms"
    metric_type: histogram
    labels:
      - step_name

  - name: api_key_validations
    pattern: "API key validation (success|failed)"
    metric_type: counter
    labels:
      - status

  - name: rate_limit_decisions
    pattern: "Rate limit (allowed|denied)"
    metric_type: counter
    labels:
      - decision
