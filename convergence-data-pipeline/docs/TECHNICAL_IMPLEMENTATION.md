# Technical Implementation Guide

## Overview

This guide consolidates all technical implementation details for the Convergence Data Pipeline, which uses a **single-dataset-per-tenant architecture** with templated pipelines and encrypted credential storage.

## System Architecture

### Single-Dataset-Per-Tenant Model

Each tenant has exactly ONE BigQuery dataset that contains all their data:

```
Dataset Structure:
{tenant_id}/
├── Metadata Tables
│   ├── pipeline_runs      - Pipeline execution tracking
│   ├── step_logs          - Individual step execution logs
│   ├── dq_results         - Data quality validation results
│   ├── api_keys           - Encrypted API keys for authentication
│   └── cloud_credentials  - Encrypted cloud provider credentials
└── Pipeline Data Tables
    └── {custom_tables}    - Generated by pipeline executions
```

**Example**: Tenant `acmeinc_23xv2` has a single dataset `acmeinc_23xv2` containing all tables.

### Template Resolution System

Pipeline configurations use template variables that are dynamically resolved at runtime:

**Template Variables**:
- `{tenant_id}` - Tenant identifier (e.g., `acmeinc_23xv2`)
- `{provider}` - Cloud provider (`gcp`, `aws`, `openai`, `anthropic`)
- `{domain}` - Service domain (`cost`, `usage`, `billing`)
- `{template_name}` - Template filename without extension
- `{pipeline_id}` - Auto-generated: `{tenant_id}-{provider}-{domain}-{template_name}`

**Template Directory Structure**:
```
configs/
├── {provider}/
│   └── {domain}/
│       └── {template_name}.yml
└── customer/
    └── onboarding-template.yml
```

**Example**:
```yaml
# Template: configs/gcp/cost/bill-sample-export-template.yml
pipeline_name: "{pipeline_id}"
steps:
  - name: "extract_billing_data"
    output:
      dataset: "{tenant_id}"
      table: "gcp_billing_export_transformed"

# Resolved for tenant "acmeinc_23xv2":
pipeline_name: "acmeinc_23xv2-gcp-cost-bill-sample-export-template"
steps:
  - name: "extract_billing_data"
    output:
      dataset: "acmeinc_23xv2"
      table: "gcp_billing_export_transformed"
```

### KMS Encryption System

All sensitive data (API keys, credentials) is encrypted using Google Cloud KMS:

**Encryption Flow**:
1. Plaintext value → Google Cloud KMS
2. KMS encrypts using specified key
3. Encrypted bytes stored in BigQuery
4. Decryption only when needed for pipeline execution

**Security Layers**:
- **SHA256 Hash**: Fast lookup without decryption (for API key authentication)
- **KMS Encryption**: Encrypted storage in BigQuery (BYTES type)
- **Show Once**: API keys only returned during onboarding

## Core Components

### 1. Configuration Management

**Template Resolver**
- **File**: `src/core/pipeline/template_resolver.py`
- **Functions**:
  - `resolve_template(template_path, variables) -> dict` - Load and resolve template variables
  - `get_template_path(provider, domain, template_name) -> str` - Generate template file path
- **Features**: Recursive variable replacement in strings, dicts, lists, and multi-line SQL

**Config Loader**
- **File**: `src/core/abstractor/config_loader.py`
- **Purpose**: Load and validate pipeline configuration files

**Configuration Models**
- **File**: `src/core/abstractor/models.py`
- **Purpose**: Pydantic models for pipeline configuration validation

### 2. Authentication & Security

**API Key Authentication**
- **File**: `src/app/dependencies/auth.py`
- **Function**: `verify_api_key_header()`
- **Flow**:
  1. Extract `X-API-Key` header
  2. Hash provided key (SHA256)
  3. Query `{tenant_id}.api_keys` for match
  4. Return `TenantContext` with tenant_id

**KMS Encryption**
- **File**: `src/core/security/kms_encryption.py`
- **Functions**:
  - `encrypt_value(plaintext: str) -> bytes` - Encrypt using KMS
  - `decrypt_value(ciphertext: bytes) -> str` - Decrypt using KMS
  - `encrypt_value_base64(plaintext: str) -> str` - Encrypt and encode as base64
  - `decrypt_value_base64(ciphertext_b64: str) -> str` - Decrypt from base64
- **Configuration**: Via environment variables (see Configuration section)

**Security Module**
- **File**: `src/core/security/__init__.py`
- **Exports**: Main encryption functions
- **Documentation**: `src/core/security/README.md`

### 3. Pipeline Execution

**Template-Based Pipeline Execution**
- **File**: `src/app/routers/pipelines.py`
- **Endpoint**: `POST /api/v1/pipelines/run/{tenant_id}/{provider}/{domain}/{template_name}`
- **Flow**:
  1. Authenticate tenant via API key
  2. Load template from `configs/{provider}/{domain}/{template_name}.yml`
  3. Resolve all `{variable}` placeholders
  4. Validate tenant_id matches authenticated user
  5. Execute pipeline with atomic duplicate detection
  6. Return pipeline_logging_id for tracking

**Pipeline Executor**
- **File**: `src/core/pipeline/executor.py`
- **Purpose**: Synchronous pipeline execution engine

**Async Pipeline Executor**
- **File**: `src/core/pipeline/async_executor.py`
- **Purpose**: Asynchronous pipeline execution for long-running jobs

**Pipeline Processors**
- **Directory**: `src/core/pipeline/processors/`
- **Files**:
  - `bq_to_bq.py` - BigQuery to BigQuery transformations
  - `async_bq_to_bq.py` - Async BigQuery transformations

**Data Quality**
- **File**: `src/core/pipeline/data_quality.py`
- **Purpose**: Data quality validation and checks

### 4. Customer Onboarding

**Onboarding API**
- **File**: `src/app/routers/customers.py`
- **Endpoint**: `POST /api/v1/customers/onboard`
- **Request**:
  ```json
  {
    "tenant_id": "acmeinc_23xv2"
  }
  ```
- **Response**:
  ```json
  {
    "tenant_id": "acmeinc_23xv2",
    "api_key": "acmeinc_23xv2_api_xK9mPqWz7LnR4vYt",
    "dataset_created": true,
    "tables_created": ["api_keys", "cloud_credentials", "pipeline_runs", "step_logs", "dq_results"],
    "dryrun_status": "SUCCESS",
    "message": "Customer acmeinc_23xv2 onboarded successfully"
  }
  ```

**Onboarding Workflow**:
1. Create BigQuery dataset `{tenant_id}`
2. Create 5 metadata tables from JSON schemas
3. Generate API key: `{tenant_id}_api_{random_16_chars}`
4. Hash API key (SHA256) for lookup
5. Encrypt API key (KMS)
6. Store in `{tenant_id}.api_keys` table
7. Run dryrun pipeline to validate setup

**Onboarding Configuration**
- **File**: `configs/customer/onboarding-template.yml`
- **Purpose**: Defines tables to create and dryrun pipeline

### 5. Data Storage

**BigQuery Client**
- **File**: `src/core/engine/bq_client.py`
- **Purpose**: BigQuery connection and query execution

**Metadata Initializer**
- **File**: `src/core/metadata/initializer.py`
- **Purpose**: Create metadata tables from JSON schemas
- **Architecture**: Single-dataset model (each tenant has one dataset)

**Metadata Logger**
- **File**: `src/core/metadata/logger.py`
- **Purpose**: Log pipeline execution to metadata tables

**Metadata Schemas**
- **Directory**: `configs/metadata/schemas/`
- **Files**:
  - `pipeline_runs.json` - Pipeline execution tracking
  - `step_logs.json` - Step execution logs
  - `dq_results.json` - Data quality results
  - `api_keys.json` - API key storage
  - `cloud_credentials.json` - Cloud credentials storage
- **Documentation**: `docs/metadata-schema.md`

### 6. Application Layer

**Main Application**
- **File**: `src/app/main.py`
- **Purpose**: FastAPI application entry point, router registration

**Configuration**
- **File**: `src/app/config.py`
- **Functions**:
  - `get_tenant_dataset_name(tenant_id)` - Returns dataset name for tenant
  - KMS configuration loading

**Admin Router**
- **File**: `src/app/routers/admin.py`
- **Purpose**: Administrative endpoints

**Middleware**
- **Directory**: `src/app/middleware/`
- **Purpose**: Request/response middleware

### 7. Utilities

**Logging**
- **File**: `src/core/utils/logging.py`
- **Purpose**: Centralized logging configuration

**Secrets Management**
- **File**: `src/core/utils/secrets.py`
- **Purpose**: Secret retrieval utilities

**Telemetry**
- **File**: `src/core/utils/telemetry.py`
- **Purpose**: Monitoring and observability

**Pipeline Locking**
- **File**: `src/core/utils/pipeline_lock.py`
- **Purpose**: Prevent concurrent pipeline executions (removed Firestore dependency)

**SQL Parameters**
- **File**: `src/core/utils/sql_params.py`
- **Purpose**: SQL query parameterization utilities

### 8. Data Processing Engines

**API Connector**
- **File**: `src/core/engine/api_connector.py`
- **Purpose**: External API integrations

**Polars Processor**
- **File**: `src/core/engine/polars_processor.py`
- **Purpose**: High-performance data transformations using Polars

## Configuration Files

### Environment Variables

**Required**:
```bash
# Google Cloud KMS (for API key encryption)
GCP_KMS_KEY_NAME=projects/{project}/locations/us-central1/keyRings/convergence-keyring/cryptoKeys/convergence-encryption-key

# Or use individual components:
KMS_PROJECT_ID=gac-prod-471220
KMS_LOCATION=us-central1
KMS_KEYRING=convergence-keyring
KMS_KEY=convergence-encryption-key
```

**Documentation**: `docs/ENVIRONMENT_VARIABLES.md`

### Pipeline Templates

**Available Templates**:
- `configs/gcp/cost/bill-sample-export-template.yml` - GCP billing export
- `configs/gcp/cost/usage-analytics-template.yml` - Usage analytics
- `configs/gcp/cost/cost-optimization-template.yml` - Cost optimization
- `configs/gcp/cost/resource-inventory-template.yml` - Resource inventory
- `configs/gcp/cost/performance-metrics-template.yml` - Performance metrics
- `configs/gcp/example/dryrun.yml` - Onboarding test pipeline

**Template Documentation**: `docs/pipeline-configuration.md`

### Customer Onboarding

**Template**: `configs/customer/onboarding-template.yml`

**Purpose**: Defines onboarding workflow including:
- Dataset creation
- Metadata table creation
- Dryrun pipeline execution

## API Reference

### Customer Onboarding

```bash
POST /api/v1/customers/onboard
Content-Type: application/json

{
  "tenant_id": "acmeinc_23xv2"
}
```

**Response**: API key (save it - only shown once), dataset status, table creation status

### Pipeline Execution (New Template-Based)

```bash
POST /api/v1/pipelines/run/{tenant_id}/{provider}/{domain}/{template_name}
X-API-Key: {api_key}
Content-Type: application/json

{
  "date": "2025-11-15"
}
```

**Example**:
```bash
POST /api/v1/pipelines/run/acmeinc_23xv2/gcp/cost/bill-sample-export-template
X-API-Key: acmeinc_23xv2_api_xK9mPqWz7LnR4vYt
```

**Response**: Pipeline logging ID, status, message

### Pipeline Execution (Legacy - Deprecated)

```bash
POST /api/v1/pipelines/run/{pipeline_id}
```

**Note**: This endpoint still works but is deprecated. Use template-based endpoint instead.

## Key Implementation Files

### Core Pipeline
- `src/core/pipeline/template_resolver.py` - Template variable resolution
- `src/core/pipeline/executor.py` - Pipeline execution engine
- `src/core/pipeline/async_executor.py` - Async pipeline execution
- `src/core/pipeline/data_quality.py` - Data quality validation

### Security
- `src/core/security/kms_encryption.py` - KMS encryption/decryption
- `src/app/dependencies/auth.py` - API key authentication

### API Routers
- `src/app/routers/customers.py` - Customer onboarding
- `src/app/routers/pipelines.py` - Pipeline execution
- `src/app/routers/admin.py` - Administrative operations

### Metadata
- `src/core/metadata/initializer.py` - Metadata table creation
- `src/core/metadata/logger.py` - Execution logging

### Configuration
- `src/app/config.py` - Application configuration
- `src/core/abstractor/config_loader.py` - Pipeline config loading
- `src/core/abstractor/models.py` - Configuration models

### Utilities
- `src/core/utils/logging.py` - Logging utilities
- `src/core/utils/secrets.py` - Secret management
- `src/core/utils/pipeline_lock.py` - Pipeline locking

### Data Engines
- `src/core/engine/bq_client.py` - BigQuery client
- `src/core/engine/api_connector.py` - API integrations
- `src/core/engine/polars_processor.py` - Data processing

## Security Features

### API Key Protection (Triple Layer)

1. **SHA256 Hash** - Fast lookup without decryption
2. **KMS Encryption** - Encrypted storage in BigQuery
3. **Show Once** - API key only returned during onboarding

### Tenant Isolation

- Each tenant has separate dataset
- API endpoints validate tenant_id matches authenticated user
- Cross-tenant access blocked with HTTP 403

### Credential Encryption

- All sensitive credentials encrypted via Google Cloud KMS
- API keys, GCP service accounts, OpenAI keys, etc.
- Decrypt only when needed for pipeline execution

## Deployment

### Quick Start

1. Install dependencies: `pip install -r requirements.txt`
2. Setup GCP KMS (see Configuration section)
3. Update `.env` with KMS configuration
4. Start server: `python3 -m uvicorn src.app.main:app --host 0.0.0.0 --port 8080`

**Documentation**: `docs/QUICK_START.md`

### Production Deployment

**Documentation**: `docs/DEPLOYMENT_GUIDE.md`

**Steps**:
1. Configure GCP KMS in production project
2. Update environment variables
3. Deploy API to Cloud Run / GKE
4. Test with real tenants
5. Monitor API key usage
6. Setup key rotation policy

## Additional Documentation

### Guides
- `docs/QUICK_START.md` - Quick start guide
- `docs/DEPLOYMENT_GUIDE.md` - Production deployment guide
- `docs/ONBOARDING.md` - Customer onboarding documentation
- `docs/README_SECRETS.md` - Secrets management guide

### Reference
- `docs/metadata-schema.md` - Metadata table schemas
- `docs/pipeline-configuration.md` - Pipeline configuration reference
- `docs/ENVIRONMENT_VARIABLES.md` - Environment variable reference
- `docs/IMPLEMENTATION_STATUS.md` - Implementation status tracking

### Architecture
- `ARCHITECTURE_REDESIGN.md` - Architecture redesign overview
- `IMPLEMENTATION_SUMMARY.md` - Implementation summary

## Benefits

- **Simplified Architecture**: One dataset per tenant instead of many
- **Template Reuse**: Single template serves all tenants
- **Secure Credentials**: KMS encryption for sensitive data
- **Easy Onboarding**: Single API call creates full tenant
- **Multi-Tenant Support**: Proven isolation and security
- **Backward Compatible**: Old endpoint still works (deprecated)
- **Production Ready**: Full error handling, logging, validation

## Migration Notes

- No backward compatibility with old multi-dataset architecture
- Delete old tenant-specific configs in `configs/{tenant_id}/`
- Use shared templates in `configs/{provider}/{domain}/`
- Migrate existing API keys to new encrypted storage
- Update client applications to use new endpoint format

---

**Implementation Date**: November 2025
**Status**: Complete - Ready for Production
**Architecture**: Single-Dataset-Per-Tenant with Template-Based Pipelines
