#!/bin/bash
# Load SaaS subscription plans (master data) into BigQuery
# NOTE: Daily costs are generated by pipelines, not loaded directly
# Run sp_calculate_subscription_plan_costs_daily after loading plans
set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "${SCRIPT_DIR}/config.sh"

echo "================================================"
echo "  Loading SaaS Subscription Data"
echo "================================================"
echo ""

check_requirements
check_auth
check_dataset

# ======================================================
# Part 1: Load Subscription Plans (master data)
# ======================================================

PLANS_DATA="${DATA_DIR}/subscriptions/subscription_plans.csv"
PLANS_SCHEMA="${SCHEMA_DIR}/subscription_plans.json"
PLANS_TABLE="${PROJECT_ID}:${DATASET}.subscription_plans"

if [[ -f "$PLANS_DATA" ]]; then
    log_info "Loading subscription plans (master data)..."
    log_info "  Source: ${PLANS_DATA}"
    log_info "  Target: ${PLANS_TABLE}"

    if [[ ! -f "$PLANS_SCHEMA" ]]; then
        log_warn "Schema file not found: ${PLANS_SCHEMA}"
        log_warn "Loading without explicit schema (auto-detect)"
        bq load \
            --source_format=CSV \
            --skip_leading_rows=1 \
            --replace \
            --autodetect \
            "${PLANS_TABLE}" \
            "${PLANS_DATA}"
    else
        bq load \
            --source_format=CSV \
            --skip_leading_rows=1 \
            --replace \
            --schema="${PLANS_SCHEMA}" \
            "${PLANS_TABLE}" \
            "${PLANS_DATA}"
    fi

    record_count=$(($(wc -l < "$PLANS_DATA" | tr -d ' ') - 1))
    log_info "  Loaded ${record_count} subscription plans"
    echo ""
else
    log_warn "Subscription plans file not found: ${PLANS_DATA}"
fi

# ======================================================
# Verify loaded data
# ======================================================

echo ""
log_info "Verifying subscription plans..."
bq query --use_legacy_sql=false \
    "SELECT provider, plan_name, seats, unit_price, pricing_model, status
     FROM \`${PROJECT_ID}.${DATASET}.subscription_plans\`
     ORDER BY provider, plan_name
     LIMIT 5"

echo ""
log_info "Subscription plans load complete!"
echo ""
log_info "NEXT STEP: Run pipeline to generate daily costs:"
log_info "  curl -X POST 'http://localhost:8001/api/v1/pipelines/run/{org}/saas_subscription/costs/saas_cost' \\"
log_info "    -H 'X-API-Key: \$ORG_API_KEY' -d '{}'"
